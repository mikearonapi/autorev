#!/usr/bin/env node

/**
 * YouTube Transcript Fetching Pipeline
 * 
 * Fetches transcripts for videos in the ingestion queue using:
 * 1. Supadata API (preferred - high reliability)
 * 2. YouTube page scraping as fallback
 * 3. Direct timedtext API as last resort
 * 
 * Updates youtube_videos table with transcript data and processing status.
 * 
 * Usage:
 *   node scripts/youtube-transcripts.js [options]
 * 
 * Options:
 *   --video-id <id>       Process a specific video only
 *   --limit <n>           Limit number of videos to process (default: 20)
 *   --dry-run             Don't write to database, just log actions
 *   --verbose             Enable verbose logging
 * 
 * Environment Variables:
 *   SUPADATA_API_KEY      Optional: Supadata API key for reliable transcript fetching
 *   YOUTUBE_API_KEY       Optional: YouTube Data API key (for official captions)
 *   SUPABASE_URL          Required: Supabase project URL
 *   SUPABASE_SERVICE_KEY  Required: Supabase service role key
 * 
 * @module scripts/youtube-transcripts
 */

import dotenv from 'dotenv';
dotenv.config({ path: '.env.local' });
import { createClient } from '@supabase/supabase-js';

// ============================================================================
// Configuration
// ============================================================================

const SUPADATA_API_KEY = process.env.SUPADATA_API_KEY;
const YOUTUBE_API_KEY = process.env.YOUTUBE_API_KEY;
const SUPABASE_URL = process.env.NEXT_PUBLIC_SUPABASE_URL || process.env.SUPABASE_URL;
const SUPABASE_SERVICE_KEY = process.env.SUPABASE_SERVICE_ROLE_KEY || process.env.SUPABASE_SERVICE_KEY;

// Parse command line arguments
const args = process.argv.slice(2);
const options = {
  videoId: null,
  limit: 20,
  dryRun: false,
  verbose: false
};

for (let i = 0; i < args.length; i++) {
  switch (args[i]) {
    case '--video-id':
      options.videoId = args[++i];
      break;
    case '--limit':
      options.limit = parseInt(args[++i], 10);
      break;
    case '--dry-run':
      options.dryRun = true;
      break;
    case '--verbose':
      options.verbose = true;
      break;
  }
}

// Logging helpers
const log = (...args) => console.log('[transcripts]', ...args);
const logVerbose = (...args) => options.verbose && console.log('[transcripts:verbose]', ...args);
const logError = (...args) => console.error('[transcripts:error]', ...args);

// ============================================================================
// Transcript Fetching Methods
// ============================================================================

/**
 * Fetch transcript using Supadata API (most reliable)
 * Free tier: 100 requests, paid plans available
 * 
 * @param {string} videoId - YouTube video ID
 * @returns {Promise<Object>} Transcript data with text and segments
 */
async function fetchTranscriptViaSupadata(videoId) {
  if (!SUPADATA_API_KEY) {
    throw new Error('SUPADATA_API_KEY not configured');
  }

  const url = `https://api.supadata.ai/v1/transcript?url=https://www.youtube.com/watch?v=${videoId}`;
  
  log(`  Fetching via Supadata API...`);
  
  const response = await fetch(url, {
    headers: {
      'x-api-key': SUPADATA_API_KEY
    }
  });

  if (!response.ok) {
    const errorText = await response.text();
    throw new Error(`Supadata API failed: ${response.status} - ${errorText}`);
  }

  const data = await response.json();
  
  if (!data.content || data.content.length === 0) {
    throw new Error('Supadata returned empty transcript');
  }

  // Convert Supadata format to our standard format
  const segments = data.content.map(item => ({
    start: (item.offset || 0) / 1000, // Convert ms to seconds
    duration: (item.duration || 0) / 1000,
    text: item.text || ''
  }));

  const fullText = segments.map(s => s.text).join(' ');

  return {
    text: fullText,
    segments,
    language: data.lang || 'en',
    isAutoGenerated: false, // Supadata doesn't tell us, assume manual
    source: 'supadata_api'
  };
}

/**
 * Fetch transcript using the youtube-transcript approach
 * This uses the publicly available transcript endpoint that YouTube uses internally
 * 
 * @param {string} videoId - YouTube video ID
 * @returns {Promise<Object>} Transcript data with text and segments
 */
async function fetchTranscriptViaLibrary(videoId) {
  // First, get the video page to extract transcript data
  const videoUrl = `https://www.youtube.com/watch?v=${videoId}`;
  
  log(`  Fetching page for ${videoId}...`);
  
  const response = await fetch(videoUrl, {
    headers: {
      'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
      'Accept-Language': 'en-US,en;q=0.9'
    }
  });

  if (!response.ok) {
    throw new Error(`Failed to fetch video page: ${response.status}`);
  }

  const html = await response.text();

  // Extract captions data from the page
  const captionsMatch = html.match(/"captions":\s*(\{[^}]+\})/);
  if (!captionsMatch) {
    // Try alternative pattern for player response
    const playerMatch = html.match(/ytInitialPlayerResponse\s*=\s*(\{.+?\});/s);
    if (!playerMatch) {
      throw new Error('No captions data found in video page');
    }

    try {
      const playerResponse = JSON.parse(playerMatch[1]);
      const captions = playerResponse?.captions?.playerCaptionsTracklistRenderer?.captionTracks;
      
      if (!captions || captions.length === 0) {
        throw new Error('No caption tracks available');
      }

      // Prefer English, then any language
      const track = captions.find(c => c.languageCode === 'en') || 
                    captions.find(c => c.languageCode?.startsWith('en')) ||
                    captions[0];

      if (!track?.baseUrl) {
        throw new Error('No caption track URL found');
      }

      logVerbose(`  Found caption track: ${track.languageCode} (${track.kind})`);

      // Fetch the transcript XML
      const transcriptResponse = await fetch(track.baseUrl);
      if (!transcriptResponse.ok) {
        throw new Error(`Failed to fetch transcript: ${transcriptResponse.status}`);
      }

      const transcriptXml = await transcriptResponse.text();

      // Parse XML to extract text segments
      const segments = [];
      const textMatches = transcriptXml.matchAll(/<text start="([^"]+)" dur="([^"]+)"[^>]*>([^<]*)<\/text>/g);

      for (const match of textMatches) {
        const start = parseFloat(match[1]);
        const duration = parseFloat(match[2]);
        const text = decodeHtmlEntities(match[3]);

        if (text.trim()) {
          segments.push({ start, duration, text });
        }
      }

      if (segments.length === 0) {
        throw new Error('Transcript XML contained no text segments');
      }

      // Combine into full text
      const fullText = segments.map(s => s.text).join(' ');

      return {
        text: fullText,
        segments,
        language: track.languageCode || 'en',
        isAutoGenerated: track.kind === 'asr',
        source: 'youtube_library'
      };

    } catch (parseError) {
      throw new Error(`Failed to parse player response: ${parseError.message}`);
    }
  }

  throw new Error('Could not extract captions from video page');
}

/**
 * Decode HTML entities in text
 * @param {string} text - Text with HTML entities
 * @returns {string} Decoded text
 */
function decodeHtmlEntities(text) {
  const entities = {
    '&amp;': '&',
    '&lt;': '<',
    '&gt;': '>',
    '&quot;': '"',
    '&#39;': "'",
    '&apos;': "'",
    '&#x27;': "'",
    '&#x2F;': '/',
    '&#32;': ' ',
    '\n': ' ',
    '\\n': ' '
  };

  let decoded = text;
  for (const [entity, char] of Object.entries(entities)) {
    decoded = decoded.split(entity).join(char);
  }

  // Handle numeric entities
  decoded = decoded.replace(/&#(\d+);/g, (match, code) => 
    String.fromCharCode(parseInt(code, 10))
  );
  decoded = decoded.replace(/&#x([0-9A-Fa-f]+);/g, (match, code) => 
    String.fromCharCode(parseInt(code, 16))
  );

  return decoded.trim();
}

/**
 * Alternative: Use a simple fallback if the library approach fails
 * This fetches from the timedtext API directly
 * 
 * @param {string} videoId - YouTube video ID
 * @returns {Promise<Object>} Transcript data
 */
async function fetchTranscriptFallback(videoId) {
  // Try the direct timedtext API with auto-generated captions
  const url = `https://www.youtube.com/api/timedtext?v=${videoId}&lang=en&fmt=json3`;
  
  const response = await fetch(url, {
    headers: {
      'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }
  });

  if (!response.ok) {
    throw new Error(`Timedtext API failed: ${response.status}`);
  }

  const data = await response.json();
  
  if (!data.events || data.events.length === 0) {
    throw new Error('No transcript events in response');
  }

  const segments = [];
  let fullText = '';

  for (const event of data.events) {
    if (event.segs) {
      const text = event.segs.map(s => s.utf8 || '').join('');
      if (text.trim()) {
        segments.push({
          start: (event.tStartMs || 0) / 1000,
          duration: (event.dDurationMs || 0) / 1000,
          text: text.trim()
        });
        fullText += text + ' ';
      }
    }
  }

  if (segments.length === 0) {
    throw new Error('No text segments extracted');
  }

  return {
    text: fullText.trim(),
    segments,
    language: 'en',
    isAutoGenerated: true,
    source: 'youtube_library'
  };
}

/**
 * Main transcript fetching function with fallbacks
 * @param {string} videoId - YouTube video ID
 * @returns {Promise<Object|null>} Transcript data or null if unavailable
 */
async function fetchTranscript(videoId) {
  // Build methods array - Supadata first if API key is available
  const methods = [];
  
  if (SUPADATA_API_KEY) {
    methods.push({ name: 'supadata', fn: fetchTranscriptViaSupadata });
  }
  
  methods.push(
    { name: 'library', fn: fetchTranscriptViaLibrary },
    { name: 'fallback', fn: fetchTranscriptFallback }
  );

  for (const method of methods) {
    try {
      logVerbose(`  Trying ${method.name} method...`);
      const result = await method.fn(videoId);
      log(`  ✓ Transcript fetched via ${method.name} (${result.text.length} chars)`);
      return result;
    } catch (error) {
      logVerbose(`  ${method.name} failed: ${error.message}`);
    }
  }

  return null;
}

// ============================================================================
// Main Pipeline
// ============================================================================

async function main() {
  log('Starting YouTube transcript pipeline...');
  log('Options:', options);
  
  // Show API configuration
  log('API Configuration:');
  log(`  - Supadata API: ${SUPADATA_API_KEY ? '✓ Configured' : '✗ Not configured (set SUPADATA_API_KEY for best results)'}`);
  log(`  - YouTube API:  ${YOUTUBE_API_KEY ? '✓ Configured' : '✗ Not configured'}`);

  // Validate configuration
  if (!options.dryRun && (!SUPABASE_URL || !SUPABASE_SERVICE_KEY)) {
    logError('SUPABASE_URL and SUPABASE_SERVICE_KEY are required (or use --dry-run)');
    process.exit(1);
  }

  // Initialize Supabase client
  const supabase = options.dryRun 
    ? null 
    : createClient(SUPABASE_URL, SUPABASE_SERVICE_KEY);

  // Fetch videos needing transcripts
  log('Fetching videos pending transcript...');
  let videos = [];

  if (options.dryRun) {
    // Sample video for dry run
    videos = [
      { video_id: 'dQw4w9WgXcQ', title: 'Test Video' }
    ];
    if (options.videoId) {
      videos = [{ video_id: options.videoId, title: 'Specific Video' }];
    }
  } else {
    let query = supabase
      .from('youtube_videos')
      .select('video_id, title')
      .eq('processing_status', 'pending')
      .is('transcript_text', null)
      .order('created_at', { ascending: true })
      .limit(options.limit);

    if (options.videoId) {
      query = supabase
        .from('youtube_videos')
        .select('video_id, title')
        .eq('video_id', options.videoId);
    }

    const { data, error } = await query;
    if (error) {
      logError('Failed to fetch videos:', error);
      process.exit(1);
    }
    videos = data || [];
  }

  log(`Found ${videos.length} videos to process`);

  if (videos.length === 0) {
    log('No videos need transcripts. Exiting.');
    return;
  }

  // Track statistics
  const stats = {
    processed: 0,
    success: 0,
    noTranscript: 0,
    errors: 0
  };

  // Process each video
  for (const video of videos) {
    log(`\nProcessing: ${video.video_id} - "${video.title?.slice(0, 50)}..."`);
    stats.processed++;

    try {
      const transcript = await fetchTranscript(video.video_id);

      if (!transcript) {
        log(`  ✗ No transcript available`);
        stats.noTranscript++;

        if (!options.dryRun) {
          await supabase
            .from('youtube_videos')
            .update({
              processing_status: 'no_transcript',
              processing_error: 'No transcript available from any source'
            })
            .eq('video_id', video.video_id);
        }
        continue;
      }

      // Validate transcript length
      if (transcript.text.length < 100) {
        log(`  ✗ Transcript too short (${transcript.text.length} chars)`);
        stats.noTranscript++;

        if (!options.dryRun) {
          await supabase
            .from('youtube_videos')
            .update({
              processing_status: 'no_transcript',
              processing_error: 'Transcript too short to be useful'
            })
            .eq('video_id', video.video_id);
        }
        continue;
      }

      // Success - update database
      stats.success++;

      if (options.dryRun) {
        log(`  [DRY RUN] Would save transcript (${transcript.text.length} chars, ${transcript.segments?.length || 0} segments)`);
        logVerbose(`  Preview: "${transcript.text.slice(0, 200)}..."`);
      } else {
        const updateData = {
          transcript_text: transcript.text,
          transcript_language: transcript.language,
          transcript_source: transcript.source,
          is_auto_generated: transcript.isAutoGenerated,
          transcript_segments: transcript.segments ? JSON.stringify(transcript.segments) : null,
          processing_status: 'transcript_fetched'
        };

        const { error: updateError } = await supabase
          .from('youtube_videos')
          .update(updateData)
          .eq('video_id', video.video_id);

        if (updateError) {
          logError(`  Database update failed:`, updateError);
          stats.errors++;
        } else {
          log(`  ✓ Saved transcript (${transcript.text.length} chars)`);
        }
      }

      // Rate limiting - 1 second between videos
      await new Promise(r => setTimeout(r, 1000));

    } catch (error) {
      logError(`  Failed to process:`, error.message);
      stats.errors++;

      if (!options.dryRun) {
        await supabase
          .from('youtube_videos')
          .update({
            processing_status: 'failed',
            processing_error: error.message
          })
          .eq('video_id', video.video_id);
      }
    }
  }

  // Print summary
  log('\n========================================');
  log('Transcript Pipeline Complete');
  log('========================================');
  log(`Processed:      ${stats.processed}`);
  log(`Success:        ${stats.success}`);
  log(`No transcript:  ${stats.noTranscript}`);
  log(`Errors:         ${stats.errors}`);

  if (options.dryRun) {
    log('\n[DRY RUN] No changes were made to the database');
  }
}

// Run
main().catch(error => {
  logError('Fatal error:', error);
  process.exit(1);
});

